COMET INFO: old comet version (3.1.2) detected. current: 3.1.6 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`
COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ttpro1995/crowd-counting-debug/9812f8e91306454bb2c86c7c75833e2e

cuda
Namespace(batch_size=5, datasetname='shanghaitech_rnd', decay=0.0001, epochs=301, input='/data/ShanghaiTech/part_B', load_model='', lr=0.0001, model='M4', momentum=0.9, note='M4 shanghaitech_rnd', task_id='local_M4_t2_shb_2', test=False)
cannot detect dataset_name
current dataset_name is  shanghaitech_rnd
in ListDataset dataset_name is |shanghaitech_rnd|
in ListDataset dataset_name is |shanghaitech_rnd|
len train_loader  320
M4(
  (front_cnn_1): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (front_cnn_2): Conv2d(20, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (front_cnn_3): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (front_cnn_4): Conv2d(14, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (c0): Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  (c1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  (c2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  (c3): Conv2d(60, 30, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  (c4): Conv2d(30, 15, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  (c5): Conv2d(15, 10, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  (output): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))
)
Namespace(batch_size=5, datasetname='shanghaitech_rnd', decay=0.0001, epochs=301, input='/data/ShanghaiTech/part_B', load_model='', lr=0.0001, model='M4', momentum=0.9, note='M4 shanghaitech_rnd', task_id='local_M4_t2_shb_2', test=False)
do not load, keep training
2020-04-23 18:47 Epoch[1] Loss: 274.38
2020-04-23 18:50 Epoch[1] Loss: 10.19
2020-04-23 18:52 Epoch[1] Loss: 14.75
2020-04-23 18:53 Training set Results - Epoch: 1  Avg mae: 13.02 Avg mse: 41.18 Avg loss: 46.16
batch_timer  1.23345003553124
train_timer  395.3803381779999
2020-04-23 18:54 Validation set Results - Epoch: 1  Avg mae: 69.45 Avg mse: 104.63 Avg loss: 41.68
evaluate_timer  494.94025821000014
2020-04-23 18:55 Epoch[2] Loss: 156.00
2020-04-23 18:58 Epoch[2] Loss: 3.47
2020-04-23 19:00 Epoch[2] Loss: 35.67
2020-04-23 19:02 Training set Results - Epoch: 2  Avg mae: 9.75 Avg mse: 32.70 Avg loss: 44.95
batch_timer  1.2935090125187485
train_timer  414.5965156809998
2020-04-23 19:02 Validation set Results - Epoch: 2  Avg mae: 57.74 Avg mse: 91.63 Avg loss: 40.40
evaluate_timer  539.1798762900007
2020-04-23 19:04 Epoch[3] Loss: 18.57
2020-04-23 19:06 Epoch[3] Loss: 45.77
2020-04-23 19:08 Epoch[3] Loss: 14.50
2020-04-23 19:10 Training set Results - Epoch: 3  Avg mae: 11.34 Avg mse: 38.19 Avg loss: 45.53
batch_timer  1.3080307883156195
train_timer  419.2482117620002
2020-04-23 19:11 Validation set Results - Epoch: 3  Avg mae: 59.44 Avg mse: 95.48 Avg loss: 41.33
evaluate_timer  583.7960872350013
2020-04-23 19:12 Epoch[4] Loss: 12.30
2020-04-23 19:14 Epoch[4] Loss: 240.78
2020-04-23 19:16 Epoch[4] Loss: 147.18
2020-04-23 19:19 Training set Results - Epoch: 4  Avg mae: 12.01 Avg mse: 37.14 Avg loss: 43.37
batch_timer  1.3212819507000149
train_timer  423.4915877759995
2020-04-23 19:20 Validation set Results - Epoch: 4  Avg mae: 62.80 Avg mse: 94.34 Avg loss: 38.80
evaluate_timer  628.1580848920012
2020-04-23 19:20 Epoch[5] Loss: 11.43
